{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_dataset = ds.EMNIST(root='./data', split='letters', train=True,\n",
    "                                     transform=transforms.Compose([\n",
    "                                         transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "                                         transforms.Lambda(lambda x: torch.flatten(x))  # Flatten the images\n",
    "                                     ]),\n",
    "                                     download=True)\n",
    "test_dataset = ds.EMNIST(root='./data', split='letters', train=False,\n",
    "                         transform=transforms.Compose([\n",
    "                             transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "                             transforms.Lambda(lambda x: torch.flatten(x))  # Flatten the images\n",
    "                         ]),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Calculate the number of samples to include in validation and training\n",
    "num_train = len(train_validation_dataset)\n",
    "num_val = int(num_train * 0.15)  # 15% for the validation set\n",
    "num_train -= num_val\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(train_validation_dataset, [num_train, num_val])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=False)  # Typically you don't need to shuffle the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your different model architectures (This is just an example. You should define these according to your needs)\n",
    "model_architectures = [\n",
    "    [784, 1024, 26],     # Model 1 architecture\n",
    "    [784, 1024, 2048, 26]      # Model 2 architecture\n",
    "]\n",
    "\n",
    "# Define the different learning rates you want to test\n",
    "learning_rates = [0.005, 0.001, 0.0005]\n",
    "dropout_rates = [0.3, 0.4, 0.5]\n",
    "\n",
    "for architecture in model_architectures:\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Training model with architecture {architecture} and learning rate {lr}\")\n",
    "\n",
    "        # Initialize model with the current architecture\n",
    "        model = ffn.Model(layer_sizes=architecture, dropout_rate=0.3)  # Update dropout_rate as needed\n",
    "\n",
    "        # Train the model with the current learning rate\n",
    "        # metrics = model.train(train_loader, val_loader, learning_rate=lr, epochs=10)\n",
    "        \n",
    "        best_model, best_params, best_accuracy = model.train(train_loader, val_loader, learning_rate=lr, epochs=10, best_accuracy=0.0)\n",
    "        current_accuracy = best_accuracy\n",
    "\n",
    "for architecture in model_architectures:\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Training model with architecture {architecture} and learning rate {lr}\")\n",
    "\n",
    "        # Initialize model with the current architecture\n",
    "        model = ffn.Model(layer_sizes=architecture, dropout_rate=0.0)  # Update dropout_rate as needed\n",
    "\n",
    "        # Train the model with the current learning rate\n",
    "        # metrics = model.train(train_loader, val_loader, learning_rate=lr, epochs=10)\n",
    "        \n",
    "        best_model, best_params, best_accuracy = model.train(train_loader, val_loader, learning_rate=lr, epochs=10, best_accuracy=current_accuracy)\n",
    "        \n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    \n",
    "with open('best_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
